{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tiasaxena/PySpark/blob/main/Pyspark_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzqlmfiY1_Lk"
      },
      "source": [
        "#### **1. PySpark Basic Introduction**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhl8-i5MrBSa",
        "outputId": "776250b9-100a-4e9a-b251-6fe52d2c481a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBV9IFa0z5LV"
      },
      "outputs": [],
      "source": [
        "import pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0PhhX7M0TBE"
      },
      "source": [
        "Before starting to work with PySpark, we need to start a PySpark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "0FC3u0yTz6ed",
        "outputId": "09a8a5a3-122b-4201-f6df-3678efeb0490"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e6cd9afce80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2744edf89756:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Pyspark-Demo').getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvAWYz9-0jXB",
        "outputId": "21fdfba7-3be5-4afe-eb44-93320844a196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe info:\n",
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n",
            "---------------------------------------------------------\n",
            "Type of dataframe: <class 'pyspark.sql.dataframe.DataFrame'>\n",
            "---------------------------------------------------------\n",
            "Head of dataframe: [Row(longitude='-114.310000', latitude='34.190000', housing_median_age='15.000000', total_rooms='5612.000000', total_bedrooms='1283.000000', population='1015.000000', households='472.000000', median_income='1.493600', median_house_value='66900.000000'), Row(longitude='-114.470000', latitude='34.400000', housing_median_age='19.000000', total_rooms='7650.000000', total_bedrooms='1901.000000', population='1129.000000', households='463.000000', median_income='1.820000', median_house_value='80100.000000'), Row(longitude='-114.560000', latitude='33.690000', housing_median_age='17.000000', total_rooms='720.000000', total_bedrooms='174.000000', population='333.000000', households='117.000000', median_income='1.650900', median_house_value='85700.000000'), Row(longitude='-114.570000', latitude='33.640000', housing_median_age='14.000000', total_rooms='1501.000000', total_bedrooms='337.000000', population='515.000000', households='226.000000', median_income='3.191700', median_house_value='73400.000000')]\n"
          ]
        }
      ],
      "source": [
        "# Use the first value as the column name for each column using `.option(\"header\", \"true\")`\n",
        "print(f\"Dataframe info:\")\n",
        "\n",
        "df_spark = spark.read.option('header', 'true').csv('/content/sample_data/california_housing_train.csv')\n",
        "df_spark.printSchema()\n",
        "\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "print(f\"Type of dataframe: {type(df_spark)}\")\n",
        "\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n",
        "print(f\"Head of dataframe: {df_spark.head(4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adU_DmY69dXr",
        "outputId": "25749de9-30a6-46cc-d2e4-d87fe53c4551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_spark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XMJV1r07h2J"
      },
      "source": [
        "#### **2. PySpark Dataframes**\n",
        "\n",
        "**Contents:**\n",
        "1. Pyspark Dataframes\n",
        "2. Reading the Dataset\n",
        "3. Checking the datatype of the columns\n",
        "4. Selecting columns and indexing\n",
        "5. Checking the description\n",
        "6. Adding Columns\n",
        "7. Dropping columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "cwPRUki56mCi",
        "outputId": "d38f2253-c494-4c6d-f802-4ae8e77509bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e6cd9afce80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2744edf89756:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "# Start the session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "session = SparkSession.builder.appName(\"Dataframe-Demo\").getOrCreate()\n",
        "session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKJTaneO-par",
        "outputId": "476c0f8e-d8ec-4886-97ce-ff7863836729"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "# 2. Read the dataset\n",
        "df = spark.read.option('header', 'true').csv('/content/sample_data/california_housing_train.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgl6EATj_9bA",
        "outputId": "f3f54996-890c-4975-85d5-79abb2a946c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n",
            "|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n",
            "|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n",
            "|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n",
            "|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n",
            "|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n",
            "|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n",
            "|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n",
            "|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n",
            "|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n",
            "|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n",
            "|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n",
            "|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n",
            "|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n",
            "|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n",
            "|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n",
            "|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n",
            "|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n",
            "|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n",
            "|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "df.show(), df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht1_3DPaAx-y"
      },
      "source": [
        "We can observe that the datatypes provided are all of type: string. We must include **inferSchema=True** to get to know about the accurate datatypes of each of the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "6izLwEn_Bvj2",
        "outputId": "3669cbbc-31ef-4905-a637-79fa7d9d26d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf: JavaObject, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|     ML|     F|      150.0|      60|\n",
              "|PySpark|     M|       75.0|      50|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 80);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ],
      "source": [
        "type(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei8ab5osAOKg",
        "outputId": "145e6253-d3b9-4511-8391-f98f86d5280c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.csv('/content/sample_data/california_housing_train.csv', header=True, inferSchema=True)\n",
        "\n",
        "# 3. Check the datatype of the columns\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtBYFg7-CmxA",
        "outputId": "d80cc5a7-a4e2-4552-9e85-8b9dbe9b84f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The column names are: \n",
            " ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n"
          ]
        }
      ],
      "source": [
        "# 4. Selecting columns and indexing\n",
        "print(f\"The column names are: \\n {df.columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVQmO1b2DpEe",
        "outputId": "0d55529e-1d40-49d5-937c-17b480c02b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+\n",
            "|total_rooms|latitude|\n",
            "+-----------+--------+\n",
            "|     5612.0|   34.19|\n",
            "|     7650.0|    34.4|\n",
            "|      720.0|   33.69|\n",
            "|     1501.0|   33.64|\n",
            "|     1454.0|   33.57|\n",
            "|     1387.0|   33.63|\n",
            "|     2907.0|   33.61|\n",
            "|      812.0|   34.83|\n",
            "|     4789.0|   33.61|\n",
            "|     1497.0|   34.83|\n",
            "|     3741.0|   33.62|\n",
            "|     1988.0|    33.6|\n",
            "|     1291.0|   34.84|\n",
            "|     2478.0|   34.83|\n",
            "|     1448.0|   32.76|\n",
            "|     2556.0|   34.89|\n",
            "|     1678.0|    33.6|\n",
            "|       44.0|   32.79|\n",
            "|     1388.0|   32.74|\n",
            "|       97.0|   33.92|\n",
            "+-----------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, pyspark.sql.dataframe.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ],
      "source": [
        "# pick up a column and see all the elements\n",
        "df.select(['total_rooms', 'latitude']).show(), type(df.select('longitude'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q70w87WmDpbn",
        "outputId": "24dfbdcf-3873-40ee-e19a-d56dc72dc41e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n",
            "|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n",
            "| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n",
            "|    min|            -124.35|             32.54|               1.0|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n",
            "|    max|            -114.31|             41.95|              52.0|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n",
            "+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 5. Checking the description\n",
        "df.describe().show() # .show() is used to display the data in the dataframe format, i.e, tabular format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz8UhqwEWC07"
      },
      "source": [
        "**Note:** Using **withColumn()** a new class of DataFrame is returned by adding a new column or replacing the existing column that has the same name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUPGssQLVzNV",
        "outputId": "87d88d2a-5f75-4f36-a184-b452a98d0438"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[longitude: double, latitude: double, housing_median_age: double, total_rooms: double, total_bedrooms: double, population: double, households: double, median_income: double, median_house_value: double, # of Rooms after addition of extra room: double]"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "# 6. Adding columns in PySpark dataframe\n",
        "df.withColumn('# of Rooms after addition of extra room', df['total_rooms']+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr6mCZGEW2xX",
        "outputId": "900175f0-b1fa-4f95-b544-61ffae9b4507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n",
            "|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n",
            "|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n",
            "|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n",
            "|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n",
            "|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n",
            "|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n",
            "|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n",
            "|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n",
            "|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 7. Drop the columns\n",
        "df.drop('# of Rooms after addition of extra room').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPY7KO8nX2PY"
      },
      "source": [
        "#### **3. PySpark Handling Missing Values**\n",
        "\n",
        "* Dropping Columns\n",
        "* Dropping Rows\n",
        "* Various Parameters in Dropping Fufznctionalities\n",
        "* Handling Missing Values by Mean, Median, Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ddynX_aJcJua",
        "outputId": "6f136c65-ba86-4e6d-a35a-9afec3e2ce0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85d12ac7-973b-4fe2-8487-5b97a0223fbc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85d12ac7-973b-4fe2-8487-5b97a0223fbc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pyspark_demo.csv to pyspark_demo (1).csv\n",
            "Upload failed. Please try again.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload kaggle.json file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Confirm the upload\n",
        "if 'kaggle.json' in uploaded:\n",
        "  print(\"pyspark_demo.csv from /Downloads uploaded successfully!\")\n",
        "else:\n",
        "  print(\"Upload failed. Please try again.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "WH_7XvsEcfRr",
        "outputId": "c61731c8-114f-4116-8ef9-d0400b7165ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e6cd9afce80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2744edf89756:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "session_2 = SparkSession.builder.appName('session').getOrCreate()\n",
        "session_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nt5BZZEdq2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f5e335-9e4a-4b72-885f-0530f001ffaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.csv('/content/pyspark_demo.csv', header=True, inferSchema=True)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjRSEadfeCru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c8a419-5f6b-475f-8590-cf55804680ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| Age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|NULL|      NULL| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      NULL|  NULL|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. Drop the columns\n",
        "df.drop('Name').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WecmXF7qeJBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ae35944-6c39-4e69-c31c-a94ddf0fd994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-5SqOt2eh0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805495ab-aed9-41f4-87e6-c621de8aa20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+------+\n",
            "| Name|Age|Experience|Salary|\n",
            "+-----+---+----------+------+\n",
            "|  Tia| 31|        10| 30000|\n",
            "|  Ria| 30|         8| 25000|\n",
            "|  Mia| 29|         4| 20000|\n",
            "|  Dia| 24|         3| 20000|\n",
            "|  Sia| 21|         1| 15000|\n",
            "|  Kia| 23|         2| 18000|\n",
            "|Mishi| 34|        10| 38000|\n",
            "+-----+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 2. Drop rows\n",
        "df.na.drop().show() # Drops all the rows with more than 1 value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGk0D6nefO2k"
      },
      "source": [
        "We can provide attribute specifying that we want to drops rows that have:\n",
        "1. All its values equal to NULL\n",
        "2. Any of its values equal to NULL.\n",
        "\n",
        "\n",
        "We can also provide a threshold values which sets the maximum limit for meeting the `all` or `any` condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1zSNYu7evFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "725319a0-87a5-4f7d-f150-708731b66740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n",
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.na.drop(how=\"any\", thresh=2).show() # atleast 2 values are not null\n",
        "df.na.drop(how=\"all\", thresh=1).show() # atleast 1 value is not null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBMVgnMg0cf"
      },
      "source": [
        "By using **`subset`** attribute, we can set the specific columns which we want to delete if there is any/all null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNqjaxlUfj3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b9b47e-a29d-403b-9ace-4848420af613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+------+\n",
            "| Name|Age|Experience|Salary|\n",
            "+-----+---+----------+------+\n",
            "|  Tia| 31|        10| 30000|\n",
            "|  Ria| 30|         8| 25000|\n",
            "|  Mia| 29|         4| 20000|\n",
            "|  Dia| 24|         3| 20000|\n",
            "|  Sia| 21|         1| 15000|\n",
            "|  Kia| 23|         2| 18000|\n",
            "|Mishi| 34|        10| 38000|\n",
            "+-----+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.na.drop(how=\"any\", subset=[\"Experience\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "535QetSHhTk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760ddcc8-c0c3-4879-f5d6-64bad45d8944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Filling the missing values\n",
        "df.na.fill('Missing Values', ['Age', 'Experience']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeGV2UZChhOw"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "  inputCols=['Age', 'Experience', 'Salary'],\n",
        "  outputCols=[\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
        ").setStrategy(\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTwCUJ22jeWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183e393e-c51a-4712-de8d-5e055c85e659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+-----------+------------------+--------------+\n",
            "| Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
            "+-----+----+----------+------+-----------+------------------+--------------+\n",
            "|  Tia|  31|        10| 30000|         31|                10|         30000|\n",
            "|  Ria|  30|         8| 25000|         30|                 8|         25000|\n",
            "|  Mia|  29|         4| 20000|         29|                 4|         20000|\n",
            "|  Dia|  24|         3| 20000|         24|                 3|         20000|\n",
            "|  Sia|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Kia|  23|         2| 18000|         23|                 2|         18000|\n",
            "|  Pia|NULL|      NULL| 40000|         28|                 5|         40000|\n",
            "|Mishi|  34|        10| 38000|         34|                10|         38000|\n",
            "|Kishu|  36|      NULL|  NULL|         36|                 5|         25750|\n",
            "+-----+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "imputer.fit(df).transform(df).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Pyspark Dataframes- Filter Operations**\n",
        "* Filter Operation\n",
        "* &, |, ==\n",
        "* ~"
      ],
      "metadata": {
        "id": "4HVBEMeLkzjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "session_2 = SparkSession.builder.appName('session').getOrCreate()\n",
        "session_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "w47lmz7KlEHt",
        "outputId": "f1d7aa75-b520-4e1b-9883-fd522310ab88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e6cd9afce80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2744edf89756:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.read.csv('/content/pyspark_demo.csv', header=True, inferSchema=True)\n",
        "\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CuR5NV6l1b5",
        "outputId": "9a8bc555-217e-44d5-b67d-4edb5f71d642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+----------+------+\n",
            "| Name| Age|Experience|Salary|\n",
            "+-----+----+----------+------+\n",
            "|  Tia|  31|        10| 30000|\n",
            "|  Ria|  30|         8| 25000|\n",
            "|  Mia|  29|         4| 20000|\n",
            "|  Dia|  24|         3| 20000|\n",
            "|  Sia|  21|         1| 15000|\n",
            "|  Kia|  23|         2| 18000|\n",
            "|  Pia|NULL|      NULL| 40000|\n",
            "|Mishi|  34|        10| 38000|\n",
            "|Kishu|  36|      NULL|  NULL|\n",
            "+-----+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter all the Names, Age of people with Salary >= 25,000\n",
        "df.filter('Salary>=25000').select(['Name', 'Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwSuxjNNmFnD",
        "outputId": "8c505fda-1429-4a18-a630-0c63365da2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+\n",
            "| Name| Age|\n",
            "+-----+----+\n",
            "|  Tia|  31|\n",
            "|  Ria|  30|\n",
            "|  Pia|NULL|\n",
            "|Mishi|  34|\n",
            "+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((df['Salary']>=2500) & (df['Salary']<=38000)).select(['Name', 'Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bt_X1rfmmZT",
        "outputId": "3abbca40-7bdd-4061-b890-964e865ac950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|  Tia| 31|\n",
            "|  Ria| 30|\n",
            "|  Mia| 29|\n",
            "|  Dia| 24|\n",
            "|  Sia| 21|\n",
            "|  Kia| 23|\n",
            "|Mishi| 34|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(~(df['Salary']>=25000)).select(['Name', 'Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRHm2PConD39",
        "outputId": "0019602c-b9bb-4e3c-d681-97238e1cd515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|Name|Age|\n",
            "+----+---+\n",
            "| Mia| 29|\n",
            "| Dia| 24|\n",
            "| Sia| 21|\n",
            "| Kia| 23|\n",
            "+----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **PySpark-GroupBy and Aggregate Functions**\n"
      ],
      "metadata": {
        "id": "0KQJ8mu0ny4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload pyspark_demo2.csv file from /Downloads\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'pyspark_demo2.csv' in uploaded:\n",
        "  print(\"pyspark_demo2.csv uploaded successfully!\")\n",
        "else:\n",
        "  print(\"Upload failed. Please try again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "5aGG1Jucn84Z",
        "outputId": "f575e52e-2a0d-458b-f9c6-d523b9bb28ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7e15567-9957-4444-b9d3-af0ee65d614b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7e15567-9957-4444-b9d3-af0ee65d614b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pyspark_demo2.csv to pyspark_demo2.csv\n",
            "pyspark_demo2.csv uploaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "session = SparkSession.builder.appName('Agg').getOrCreate()\n",
        "session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "2GiyxoTWqQFJ",
        "outputId": "bb7d650b-4ed5-4d26-d5fd-c320fb85851d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e6cd9afce80>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2744edf89756:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark-Demo</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/pyspark_demo2.csv', header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9byAPU6ZqbxM",
        "outputId": "156ea2a2-bbea-49b8-a936-9461d84a044e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------+\n",
            "|     Name| Departments|Salary|\n",
            "+---------+------------+------+\n",
            "|    Krish|Data Science| 10000|\n",
            "|    Krish|         IOT|  5000|\n",
            "|   Mahesh|    Big Data|  4000|\n",
            "|    Krish|    Big Data|  4000|\n",
            "|   Mahesh|Data Science|  3000|\n",
            "|Sudhanshu|Data Science| 20000|\n",
            "|Sudhanshu|         IOT| 10000|\n",
            "|Sudhanshu|    Big Data|  5000|\n",
            "|    Sunny|Data Science| 10000|\n",
            "|    Sunny|    Big Data|  2000|\n",
            "+---------+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the total salary of each of the employees\n",
        "df.groupBy('Name').sum('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A2lE51HsBLP",
        "outputId": "a5068d10-5d37-4136-8e54-57e1c41b8d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|sum(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|      35000|\n",
            "|    Sunny|      12000|\n",
            "|    Krish|      19000|\n",
            "|   Mahesh|       7000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by departments which gives maximum salary\n",
        "df.groupBy('Departments').mean('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVy4ynhtsJVP",
        "outputId": "3c524bd2-8579-41b7-a622-b5863e0d7293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n",
            "| Departments|avg(Salary)|\n",
            "+------------+-----------+\n",
            "|         IOT|     7500.0|\n",
            "|    Big Data|     3750.0|\n",
            "|Data Science|    10750.0|\n",
            "+------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of employees working in each department\n",
        "df.groupby('Departments').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx4HNx7Lsia-",
        "outputId": "06ca8b30-c460-40da-a5ad-e57d7a644e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "| Departments|count|\n",
            "+------------+-----+\n",
            "|         IOT|    2|\n",
            "|    Big Data|    4|\n",
            "|Data Science|    4|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Total and mean of the salaries\n",
        "df.agg({'Salary': 'mean'}).show(), df.agg({'Salary': 'sum'}).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boBzDfIXsv2h",
        "outputId": "72c77d7f-c69e-49bc-9229-5236e85aeba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|avg(Salary)|\n",
            "+-----------+\n",
            "|     7300.0|\n",
            "+-----------+\n",
            "\n",
            "+-----------+\n",
            "|sum(Salary)|\n",
            "+-----------+\n",
            "|      73000|\n",
            "+-----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the minimum salary of ea ch of the employee\n",
        "df.groupBy('Name').min('Salary').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZiUFuNftAjn",
        "outputId": "2af4fe62-cf09-48e5-df39-afd509b34d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|     Name|min(Salary)|\n",
            "+---------+-----------+\n",
            "|Sudhanshu|       5000|\n",
            "|    Sunny|       2000|\n",
            "|    Krish|       4000|\n",
            "|   Mahesh|       3000|\n",
            "+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fzqlmfiY1_Lk",
        "4XMJV1r07h2J",
        "xPY7KO8nX2PY",
        "4HVBEMeLkzjk"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOYiwx3LS4UpBTuBfmBDqGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}